{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC160 Data Science and the Arts - Twomey - Spring 2020 - [dsc160.roberttwomey.com](http://dsc160.roberttwomey.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensional Reduction\n",
    "\n",
    "This notebook explores techniques for dimensional reduction and visualization for high dimensional data (n>2) using python and jupyter. Dimensional reduction is a key problem in working with feature vectors and high dimensional data: how do we plot or reduce data from some higher dimensional space (n > 2) to a manageable lower dimensional space. \n",
    "\n",
    "For our purposes, an audio feature vector could contain 10-20 points (zero crossing rate, spectral centroid, MFCCs 0-20, etc.), or a visual feature vector could be extracted from an image using a pretrained Convolutional Neural Network.\n",
    "\n",
    "Implements the following techniques:\n",
    "- Principal Component Analysis (PCA) https://scikit-learn.org/stable/modules/decomposition.html#pca\n",
    "- Multi-Dimensional Scaling (MDS)\n",
    "- t-Distributed Stochastic Neighbor Embedding (t-SNE) https://lvdmaaten.github.io/tsne/\n",
    "- Uniform Manifold Approximation and Projection (UMAP) for Dimension Reduction [https://arxiv.org/abs/1802.03426](https://arxiv.org/abs/1802.03426)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Principal Component Analysis (PCA) - (from [wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis))\n",
    "\n",
    "Given a collection of points in two, three, or higher dimensional space, a \"best fitting\" line can be defined as one that minimizes the average squared distance from a point to the line. The next best-fitting line can be similarly chosen from directions perpendicular to the first. Repeating this process yields an orthogonal basis in which different individual dimensions of the data are uncorrelated. These basis vectors are called principal components, and several related procedures principal component analysis (PCA). \n",
    "\n",
    "PCA is mostly used as a tool in exploratory data analysis and for making predictive models. It is often used to visualize genetic distance and relatedness between populations. PCA is either done in the following 2 steps:\n",
    "\n",
    "1. calculating the data covariance (or correlation) matrix of the original data\n",
    "2. performing eigenvalue decomposition on the covariance matrix\n",
    "\n",
    "PCA is a linear dimensional reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lets load the DIGITS data set of hand written digits from `sklearn.datasets` and print the description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits dataset is a collection of low res (8x8) grayscale images of handwritten digits. It is a common dataset for image classification and handwriting recognition research. \n",
    "\n",
    "To work with this data for a PCA analysis, we will first normalize the scale of the image data (divide by 255 to normalize from `0.0` to `1.0`). We will also grab the labels for the digit data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data / 255.0\n",
    "y = digits.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets store the digits data in a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['y'] = y\n",
    "df['label'] = df['y'].apply(lambda i: str(i))\n",
    "# X, y = None, None\n",
    "print('Size of the dataframe: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducability of the results\n",
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,15):\n",
    "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'label'])) )\n",
    "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((8,8)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df.loc[rndperm,:],\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "# ax.scatter(\n",
    "#     xs=df.loc[rndperm,:][\"pca-one\"], \n",
    "#     ys=df.loc[rndperm,:][\"pca-two\"], \n",
    "#     zs=df.loc[rndperm,:][\"pca-three\"], \n",
    "#     c=df.loc[rndperm,:][\"y\"], \n",
    "#     cmap='tab10'\n",
    "# )\n",
    "# ax.set_xlabel('pca-one')\n",
    "# ax.set_ylabel('pca-two')\n",
    "# ax.set_zlabel('pca-three')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dimensional Scaling\n",
    "\n",
    "Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. MDS is used to translate \"information about the pairwise 'distances' among a set of n objects or individuals\" into a configuration of n points mapped into an abstract Cartesian space. \n",
    "\n",
    "It is a form of non-linear dimensionality reduction.\n",
    "(from [wikipedia](https://en.wikipedia.org/wiki/Multidimensional_scaling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits = load_digits()\n",
    "# X = digits.data / 255.0\n",
    "# y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = MDS(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = embedding.fit_transform(X[:100])\n",
    "# X_transformed = embedding.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = pd.DataFrame(X_transformed)\n",
    "small_df['y'] = y[:len(X_transformed)]\n",
    "# small_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=X_transformed[:,0], y=X_transformed[:,1],\n",
    "    hue='y',\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=small_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "\n",
    "T-distributed Stochastic Neighbor Embedding (t-SNE) is a machine learning algorithm for visualization developed by Laurens van der Maaten and Geoffrey Hinton. It is a nonlinear dimensionality reduction technique well-suited for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions. Specifically, it models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.\n",
    "\n",
    "The t-SNE algorithm comprises two main stages. First, t-SNE constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects have a high probability of being picked while dissimilar points have an extremely small probability of being picked. Second, t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimizes the Kullback–Leibler divergence (KL divergence) between the two distributions with respect to the locations of the points in the map. (from [wikipedia](https://en.wikipedia.org/wiki/Multidimensional_scaling))\n",
    "\n",
    "good online demo to explore the concept: https://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(X)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tsne_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3,\n",
    "    ax=ax1\n",
    ")\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3,\n",
    "    ax=ax2\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP\n",
    "\n",
    "\n",
    "Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction\n",
    "technique that can be used for visualisation similarly to t-SNE, but also for\n",
    "general non-linear dimension reduction. The algorithm is founded on three\n",
    "assumptions about the data\n",
    "\n",
    "1. The data is uniformly distributed on Riemannian manifold;\n",
    "2. The Riemannian metric is locally constant (or can be approximated as such);\n",
    "3. The manifold is locally connected.\n",
    "\n",
    "From these assumptions it is possible to model the manifold with a fuzzy\n",
    "topological structure. The embedding is found by searching for a low dimensional\n",
    "projection of the data that has the closest possible equivalent fuzzy\n",
    "topological structure.\n",
    "\n",
    "The details for the underlying mathematics can be found in\n",
    "[their paper on ArXiv](https://arxiv.org/abs/1802.03426)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once\n",
    "# !pip uninstall -y umap --user\n",
    "!pip install umap-learn --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP with Iris Data\n",
    "\n",
    "Below is the UMAP example with iris data from https://umap-learn.readthedocs.io/en/latest/basic_usage.html#iris-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn for plotting, we can also use bokeh\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = pd.Series(iris.target).map(dict(zip(range(3),iris.target_names)))\n",
    "sns.pairplot(iris_df, hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bad workaround, see here: https://github.com/lmcinnes/umap/issues/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(iris.data)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in iris.target])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the Iris dataset', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP with DIGITS data\n",
    "\n",
    "Below is the UMAP example with DIGITS data https://umap-learn.readthedocs.io/en/latest/basic_usage.html#digits-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(20, 20)\n",
    "axes = ax_array.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[i], cmap='gray_r')\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_df = pd.DataFrame(digits.data[:,:10])\n",
    "digits_df['digit'] = pd.Series(digits.target).map(lambda x: 'Digit {}'.format(x))\n",
    "sns.pairplot(digits_df, hue='digit', palette='Spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do the UMAP reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "reducer.fit(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.transform(digits.data)\n",
    "# Verify that the result of calling transform is\n",
    "# idenitical to accessing the embedding_ attribute\n",
    "assert(np.all(embedding == reducer.embedding_))\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10), dpi=80)\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=digits.target, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP projection of the Digits dataset', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view these results with bokeh and tooltips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddable_image(data):\n",
    "    img_data = 255 - 15 * data.astype(np.uint8)\n",
    "    image = Image.fromarray(img_data, mode='L').resize((64, 64), Image.BICUBIC)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format='png')\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return 'data:image/png;base64,' + base64.b64encode(for_encoding).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
    "digits_df['digit'] = [str(x) for x in digits.target]\n",
    "digits_df['image'] = list(map(embeddable_image, digits.images))\n",
    "\n",
    "datasource = ColumnDataSource(digits_df)\n",
    "color_mapping = CategoricalColorMapper(factors=[str(9 - x) for x in digits.target_names],\n",
    "                                       palette=Spectral10)\n",
    "\n",
    "plot_figure = figure(\n",
    "    title='UMAP projection of the Digits dataset',\n",
    "    plot_width=600,\n",
    "    plot_height=600,\n",
    "    tools=('pan, wheel_zoom, box_zoom, reset')\n",
    ")\n",
    "\n",
    "plot_figure.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src='@image' style='float: left; margin: 5px 5px 5px 5px'/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style='font-size: 16px; color: #224499'>Digit:</span>\n",
    "        <span style='font-size: 18px'>@digit</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot_figure.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color=dict(field='digit', transform=color_mapping),\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4\n",
    ")\n",
    "show(plot_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- UMAP reference here https://umap-learn.readthedocs.io/en/latest/basic_usage.html#digits-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
